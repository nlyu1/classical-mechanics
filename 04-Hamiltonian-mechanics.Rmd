# Hamiltonian Mechanics 

We begin by exporing the properties of the Legendre 
transform, which relates (convex) Lagrangians and Hamiltonians. 
We next introduce Hamilton's equations, with some 
optional perspective from differential geometry 
which yield some of the most mathematically satisfactory / beautiful 
treatment of the topic. 

Key takeaways of this part are: 

1. The Hamiltonian $H(q, p, t)$ is the Legendre transform of $\mca L(q, \dot q, t)$ 
    fixing $q, t$; fixing $q, t$, the conjugate variables 
    $\dot q$ and $p$ are functions 
    of each other by $\nabla_{\dot q} \mca L = p$ and $\dot q = \nabla_p H$ 
    (lemma \@ref(lem:legendreConjugateRelation)). 
    The Jacobian $J_{p\to q}$ is the Hessian. 
2. When the $\sup$ is dropped in the Legendre transform, 
    the two variables are always understood to obey 
    an implicit equation.
3. On strictly convex functions, the Legendre transform _preserves 
    convexity, and is involutary_. 
4. The scalar Hamiltonian function $H(q, p, t)\in \R$ 
    generates the flow of time in phase space, or time-translation symmetry. 
5. Converse to Noether's theorem: every scalar function on phase space 
    generates a flow corresponding to its continuous symmetry: 

## Legendre transform {-}

The Legendre transform is a general transform of functions 
which interactive particularly well with convex functions. 

:::{.definition name="Legendre transform"}
Given a function $f:\R^n\to \R$, its Legendre transform 
$\mbb L f: \R^n\to \R$ is 
\[ 
    (\mbb L f)(p) = \sup_x \, \la x, p\ra - f(x)
\] 
:::

### Convex functions {-}
Convex functions are characterized by 
\[ 
    f(\lambda x + \bar \lambda y) \leq \lambda f(x) + \bar \lambda f(y), \quad 
    \lambda \in [0, 1], \bar \lambda = 1 - \lambda 
\] 
assume they're well-behaved enough, they're equivalently defined by 
having positive (semi) definite second-derivatives (Hessian) at all points: 
\[ 
    (\mca H_x f)(\forall x) \geq 0, \quad 
    (\mca H_x f)_{ij}(x) = (\pd {x_i x_j}^2 f)(x)
\] 
Here $A\geq 0$ for matrix $A$ is understood 
as _all_ eigenvalues of $A$ being nonnegative. Convexity is further 
equivalent to 
\[ 
    \forall x, y: f(y) \geq \nabla f(x) \cdot (y - x)
\] 
The function $f$ is _strictly convex_ when the inequalities are strict. 

:::{.proposition}
The gradient map $x\mapsto (\nabla f)(x)$ is invertible 
if $f$ is strictly convex. 
:::
_Proof:_ For $x\neq y$, strict convexity implies 
\begin{align}
    \nabla f(x) \cdot (y-x) < f(y) - f(x), \quad 
    \nabla f(y) \cdot (x-y) < f(x) - f(y)
\end{align}
Suppose for contradiction that $\nabla f(x) = \nabla f(y)$, 
substituting $\nabla f(y)=\nabla f(x)$ in the last equation and 
multiplying both sides by $-1$ yields the contradiction 
\[ 
    \nabla f(x)\cdot (y-x) > f(y) - f(x)
\] 

### Properties of the Legendre transform {-}
We now show that the Legendre transform is well-behaved 
for strictly convex functions. 

Assuming $f$ well-behaved, the extremality condition is 
\[ 
    \nabla_x \la x, p\ra - f(x) 
    = p - \nabla_x f(x) = 0 \iff p = \nabla_x f 
\] 
This means that the $\sup$ may be dropped
<span style="color:green">
when it is understood that $x$ is an implict function of 
$p$ via the equation $p = \nabla_x f$ 
</span>: 
\[ 
    (\mbb L f)(p=\nabla_x f) = x\cdot p - f(x)
\] 

The following lemma will prove the Hamilton 
equation $\dot q = \nabla_p H$. 

:::{.lemma #legendreConjugateRelation name="two-way relation between x and p"}
Given a Legendre transform 
\[ 
    g(p) = (\mbb L f)(p) = \sup_x p\cdot x - f(x)
\] 
Then $p = \nabla_x f \iff x = \nabla_p g$. 
:::
_Proof:_ Assuming $p = \nabla_x f$, then we can 
drop the $\sup$ in the Legendre transform, yielding 
\[ 
    g(p) = p\cdot x - f(x)
\] 
Take the gradient w.r.t. $p$ on both sides; note that 
we need to invoke the chain rule since $p, x$ are related: 
\begin{align}
    \nabla_p g(p) 
    &= \nabla_p (p\cdot x - f(x)) 
    = x + J_{p\to x} p - J_{p\to x} (\nabla_x f)_{=p}
    = x 
\end{align}

:::{.proposition name="Jacobian of Legendre transform"}
The Jacobian of the Legendre transform $x\to p$ is the Hessian of $f$ 
\[ 
    J_{x\to p} = d_x p = d_x \left(\nabla_x f\right) = \mca H_x f 
\] 
:::

:::{.proposition name="convexity invariance"}
Suppose $f(x)$ is convex strictly convex so $\mca H_x f> 0$ 
(positive-definite) everywhere, then $\mbb L f$ 
is convex, i.e. $\mca H_p (\mbb L f)>0$. 
:::
_Proof:_ Computing the Hessian explicitly and recognize $\nabla_x f = p$
\begin{align}
    \mca H_p(\mbb L f) 
    &= d_p [\nabla_p (\mbb L f)] = d_p \left[
        x + J_{p\to x} p - J_{p\to x}\nabla_x f
    \right] \\ 
    &= d_p x = J_{p\to x} = J_{x\to p}^{-1} = \left(\mca H_x f\right)^{-1}
\end{align}
Convexity follows from the convexity of $\mca H_x f> 0$. 

:::{.proposition name="involutary"}
For convex $f$, the Legendre transform is involutary 
\[ 
    \mbb L \left[(\mbb L f)(p)\right] (x) = f(x)
\] 
:::
_Proof:_ Unroll the definition
\begin{align}
    \mbb L \left[(\mbb L f)(p)\right] (x)
    &= \mbb L \left[p\mapsto xp - f(x)\right] (x)\\ 
    &= xp - \left[p\mapsto xp - f(x)\right]\, p 
    = xp - xp - f(x) = f(x)
\end{align}
Note the dependence here: fixing $x$, we can fix $p=\nabla_x f$, which 
in turn determines $x$ in the inner Legendre transform. 


## Hamilton's equations {-}

:::{.definition name="Hamiltonian"}
Given the Lagrangian $\mca L(q, \dot q, t)$, the 
    Hamiltonian is the Legendre transform of $\dot q\mapsto p$ 
    holding $q$ fixed 
    \[ 
        H(q, p, t) = p\cdot \dot q - \mca L(q, \dot q(p), t)
    \] 
    where $p = \nabla_{\dot q} \mca L$ and $\dot q(p)$ 
    is the implicit inverse of this equation. 
:::

:::{.theorem #hamiltonEquations name="Hamilton's equations"} 
The following equations are equivalent to the Euler-Lagrange 
    equations \@ref(def:eulerLagrange) when the Lagrangian 
    $\mca L(q, \dot q, t)$ is strictly convex in in $\dot q$: 
    \begin{aligned}
        \dot p 
        = -\nabla_q H, \quad \dot q 
        = \nabla_p H 
    \end{aligned}
    Collecting $\xi = q \oplus p$ i.e. $(\xi_1, \xi_2, \dots, \xi_{2n} = (q_1, p_1, q_2, \dots q_n, p_n)$ 
    and write $H(q, p, t) = H(\xi, t)$, we obtain the compact expression 
    \[ 
        \pd t \xi = \Gamma\,  \nabla_\xi H, \quad \Gamma 
        = \bigoplus \begin{pmatrix}
            0 & 1 \\ -1 & 0 
        \end{pmatrix}
        (\#eq:omegaForm)
    \] 
:::
_Proof:_ Take care that $\dot q, p$ are implicit functions of each other 
    and recognize $p=\nabla_{\dot q}\mca L$; holding $q$ fixed: 
    \begin{align}
        \nabla_p H(q, p, t) 
        &= \nabla_p \left[p\cdot \dot q - \mca L(q, \dot q(p), t)\right] \\ 
        &= \dot q + J_{p\to \dot q} p - J_{p\to \dot q}(\nabla_{\dot q}\mca L) 
        = \dot q 
    \end{align}
    For the second equation, we're holding $p$ fixed, but $\dot q$ is still 
    dependent upon $q$, then 
    \begin{align}
        \nabla_q H(q, p, t) 
        &= \nabla_q \left[
            p\cdot \dot q - \mca L(q, \dot q(p), t)
        \right] \\ 
        &= J_{q\to \dot q}p 
        - \nabla_q \mca L - J_{q\to \dot q} (\nabla_{\dot q}\mca L) 
        = - \nabla_q \mca L  \\ 
        \dot p 
        &= d_t \nabla_{\dot q}\mca L = \nabla_q \mca L 
    \end{align}
    the last equation holds by the Euler-Lagrange equations. 

## Differential geometry perspective {-}

<div style="color:green">
Hamilton's equations $\pd t \xi = \Gamma \, \nabla_\xi H$ 
is the component representation of the following implicit 
equation which defines the vector field $X_H$ 
_generating the time-translation of the system_: 
\[ 
    \omega(X_H, \, \cdot\, ) = dH
\] 
Here $\omega= dq \wedge dp = \sum_j dq_j\wedge dp_j$ 
is the _symplectic form_ represented by $\Gamma$, and $dH$ 
is the differential of $H$. 
</div> 
How is this an implicit equation? Both sides 
of the equation consumes a vector field to output 
a scalar, and $X_H$ is implicitly defined to satisfy the equation. 

We next proceed to showing that this is, in fact, 
equivalent to Hamilton's equations. 

:::{.remark name="differential geometry basics"}
Given a chart $x=(x_1, \cdots, x_n)$ on a manifold $M$ (like fixing 
a basis), a **vector field** $X$ can be understood as a _directional derivative_ 
operation that consumes a scalar function $f$ and outputs $X\, f$ (read as 
$X$ acting on $f$. The value of $(X\, f)(x)$ encodes how much $f$ 
changes along the direction of the vector field $X$ at location $x$. 
The representation of $X$ in this chart $x$ is then 
\[ 
    X = \sum_{j=1}^n X_j \pd j 
\] 
where each $X_j$ is a scalar function and $\pd j = \pd {x_j}$ 
denotes the partial differentiation operation in the $j$-th variable; 
in this representation, the action of $X$ can be locally written 
in coordinate form as 
\[ 
    (X\, f)(x) = \sum_{j=1}^n X_j \pd j f(x) = (X_j)\cdot \nabla f(x)
\] 
Here $(X_j)$ is understood as a vector denoting the "direction"; 
in this sense the chart $x$ also fixes a basis $\pd 1, \cdots \pd n$ 
for the space of vector fields (tangent bundle). 
Given a scalar function $f$, its **differential** $df$ consumes a vector 
field and outputs a scalar (function)
\[
    df\, X = X\, f 
\] 
We can similarly consider a basis representation for the differentials 
(which live on the cotangent bundle) with the notation $d x_1, \cdots, dx_n$ 
\[ 
    df = \sum_{j=1}^N f_j dx_j, \quad dx_j\, \pd i = \delta_{ij}
\] 
:::

The last piece we need is **the wedge product**: assuming a basis 
$B=\{\pd p, \pd q\}$ ($p$, $q$ are univariables), the symplectic form 
$\omega = dq \wedge dp$ consumes two arguments in $B$ and outputs a number 
subject to the following rules, in addition to being linear in all its arguments: 
\[ 
    (dq \wedge dp)(\pd a, \pd b) = \begin{cases}
        1 & (\pd a, \pd b) = \pd q, \pd p \\ 
        -1 & (\pd a, \pd b) = \pd p, \pd q \\ 
        0 & \text{otherwise}. 
    \end{cases}
\] 

Back to Hamilton's equation $\omega(X_H, \cdot) = dH$. 
Fix the basis $\{\pd q, \pd p\}$ (the order matters!)
and consider two vector fields $X, Y$ with components 
\[ 
    X = X_q \pd q + X_p \pd p, \quad Y = Y_q \pd q + Y_p \pd p 
\] 
The representation $\Gamma$ of $\omega$ is read from the equation 
\begin{align}
    \omega(X, Y) 
    &= X_qY_q \omega(\pd q, \pd q)_{=0} + X_p Y_q \omega(\pd p, \pd q)_{=-1}
    + X_qY_p \omega (\pd q, \pd p)_{=1} + X_pY_p \omega (\pd p, \pd p)_{=0} \\ 
    &= X_qY_p - X_p Y_q 
    = \begin{pmatrix} X_q \\ X_p \end{pmatrix}^T 
    \begin{pmatrix}
        0 & 1 \\ -1 & 0 
    \end{pmatrix} \begin{pmatrix}
        Y_q \\ Y_p 
    \end{pmatrix} \implies \Gamma = \begin{pmatrix}
        0 & 1 \\ -1 & 0 
    \end{pmatrix}
\end{align}
The implicit equation holds for all vector fields $Y$ 
(since both sides of the equation consume a vector field and outputs a scalar function)
\[ 
    \omega (X_H, Y) = dH\, Y = Y\, H \implies (X_H)^T \Gamma Y 
    = Y_q \pd q H + Y_p \pd p H = (\nabla H)^T Y, \quad \forall Y
\] 
where we have identified $X_H, Y$ with their $\pd q, \pd p$ coordinate 
representations on the RHS. Solving for $X_H$ yields 
\[ 
    (X_H)^T \Gamma = (\nabla H)^T \iff \nabla H = ((X_H)^T \Gamma)^T 
    = -\Gamma X_H \iff X_H = \Gamma \nabla_H 
\] 
This is exactly the component expression of Hamilton's equations 
we have derived. 
</details>

## Poisson bracket, canonical transformations {-}

From now on, we work with a system with $N$ degrees of freedom 
with phase space of dimension $2N$. Recall the definition 
of $\xi$ and $\Gamma$ in equation \@ref(eq:omegaForm). 

:::{.definition name="Poisson bracket"}
The Poisson bracket between two smooth scalar functions is 
\[
    \pb A B = \nabla_q A \cdot \nabla_p B - \nabla_p A \cdot \nabla_q B 
    = (\nabla_\xi A)^T \Gamma (\nabla_\xi B)
\]
We also use the derivative map $D_A: B\mapsto \pb A B$ to denote partial 
application of the Poisson bracket. 
:::

The quantum analogue of the following relation are the canonical 
commutation relations between $\hat x, \hat p$. They are the true 
foundational axioms which specify a theory. 

:::{.definition name="fundamental Poisson brackets"}
$\pb {q_j} {q_k} = \pb {p_j} {p_k} = 0, \pb {q_j} {p_k} = \delta_{ij}$. 
Equivalently, these quantities are "probing" the entries of $\Gamma$ 
\[
    \pb {\xi_j}{\xi_k} = \Gamma_{jk}
\]
:::

Using the Poisson brackets, Hamilton's equations (theorem \@ref(thm:hamiltonEquations)) 
can be rewritten as 
\[
    \pd t \xi = -D_H \xi \implies \xi(t) = e^{- t D_H} \xi(0).
\]
The vector field $D_H$ is also known as the **symplectic gradient** 
of $H$. The time-evolution operator for time $t$ 
is $\xi \mapsto e^{-tD_H}$. The following result shows the compatibility of the 
Jacobian map with the exponential. 

:::{.proposition name="Jacobian of an exponential transform"}
Given an exponential map $\xi \mapsto e^{-\lambda T}\xi$ 
(here $\xi$ may be an operator instead of a constant matrix!), 
assuming convergence we obtain 
$J_{\xi \mapsto e^{-\lambda T \xi}} = e^{-\lambda J_{\xi \to T\xi}}$. 
:::
_Proof:_ Note that $J_{T+S} = J_T+J_S$, and $J_{TS}=J_TJ_S$. Since 
the exponential is defined as a power series using addition and multiplication, 
we obtain $J_{\exp(T)} = \exp(J_T)$. 

:::{.theorem name="evolution of scalar under flow generated by another scalar"}
Given two scalar functions $C, G$ (observables) 
and $\xi(\lambda)=e^{-\lambda D_G} \xi(0)$, 
the observable $C$ evolves according to 
\[
    d_\lambda C = \pb C G = -D_G C 
\]
To be extremely clear about dependences, we write 
$d_\lambda C(\xi(\lambda)) = -D_G \big|_{\xi(\lambda)} C(\xi(\lambda))$, 
here $C, G$ are both implicit functions of $\lambda$ through $\xi(\lambda)$. 
:::
_Proof:_ Indices which are repeated twice are summed over (contracted), expand to obtain 
\begin{align}
    d_\lambda C 
    &= (\nabla_\xi C)\cdot d_\lambda \xi = -(\nabla_\xi C)\cdot D_G \xi  
    = (\pd {\xi_j} C) [\xi_j, G] \\ 
    &= (\pd {\xi_j} C) \pd {\xi_l} \xi_j \Gamma_{lk} (\pd {\xi_k} G)
    = (\pd {\xi_j} C)\Gamma_{jk}(\pd {\xi_k} G)
    = \pb C G 
\end{align}

:::{.corollary name="scalars are conserved under their Hamiltonian flow"}
Given a scalar function $G$ on phase space, if $\xi$ evolves according to 
the flow generated by $G$ as below, then $d_\lambda G(\xi(\lambda)) = 0$. 
\[
    d_\lambda \xi = - D_G \xi \iff \xi(\lambda) = e^{- \lambda D_G} \xi(0)
\]
:::
_Proof:_ By antisymmetry of the Poisson bracket, $d_\lambda G = \pb G G = 0$. 


:::{.theorem, name=""}
Given a scalar function $A$ and the transform induced 
by its symplectic gradient $e^{\lambda D_A}$ 
then for $J=J_{\xi \to e^{\lambda D_A}\xi$, we obtain 
\[
    J\Gamma J^T = \Gamma, \quad \det J = 1
\]
In other words, 
:::

## Liouville's theorem {-}

## Optional: probability on phase space {-}