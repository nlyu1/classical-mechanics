[["index.html", "Physics 151 F24 Notes Preface Introduction to the course Using these notes A note on notation", " Physics 151 F24 Notes Nicholas Lyu, Arthur Jaffe 2024-10-06 Preface These notes accompany the Fall 2024 iteration of Arthur Jaffe’s Mechanics course at Harvard (Physics, 151). Introduction to the course For those who learn math, at some point (late into high school or in college) there is a change of perspective from computation to proof-based math. One stops viewing matrices as large blobs of numbers but as coordinate representations of abstract linear transformations. There is a similar shift in perspective in physics, when the emphasis changes from solving equations of motion to understanding the fundamental reasons they’re there in the first place. Key to navigating this change is understanding the role of symmetry and conservation laws, as well as the importance of operators in physics. The focus of this course is not quantum theory (maybe at the end, time permitting), but the classical treatment of symmetry and conservation will help motivate much of quantum theory’s constructions. Using these notes These notes summarize and, occasionally, supplement Prof. Jaffe’s lecture notes on canvas. They are meant as a concise reminder of the main results in lecture. A note on notation It is always important to be careful about derivative maps, where overloaded notation can frequently lead to confusion. We use the following standard notation for partial derivatives: \\[ \\partial_{x_1} f(x_1, x_2) = \\dfrac{\\partial}{\\partial x_1} f(x_1, x_2) \\] For second-order derivatives, we adopt \\[ \\partial_{x_1, x_2}^2 f(x_1, x_2) = \\dfrac{\\partial^2}{\\partial x_1\\partial x_2} f(x_1, x_2) \\] We also use the following not-so-standard notation for total derivatives: \\[ d_t f(x_1(t), x_2(t)) = \\dfrac d {dt} f(x_1(t), x_2(t)) \\] When we wish to specify the point at which a derivative is evaluated, we write e.g.  \\[ d_t\\big|_0 f(x_1(t), x_2(t)) = x&#39;_1(0) \\partial_{x_1} f + x&#39;_2(0) \\partial_{x_2} f \\] "],["two-body-problem.html", "1 Two-body problem Problem setup Three conserved quantities Orbits, effective potential Scattering", " 1 Two-body problem Corrections: Lecture notes missing \\vec on \\(F_2\\) before section 2. \\(\\dot {\\vec r}\\) mis-typed after eq 28 in “angular momentum”. We start with this problem to: Warm up the physics brain if you haven’t solved a mechanicss problem in a while :) Present one of the few solvable physics problems (another being the harmonic oscillator). Exemplify how a problem can be solved by analyzing its symmetries and conserved quantities. Introduce the Runge-Lenz vector (hydrogen atom, Physics 143a), effective radial potential (Physics 143a, 210), and the basics of scattering (Physics 143b). We approach the two-body problem in the following steps: Reduce to one-body motion. Identify the conserved quantities: energy \\(E\\), angular-momentum \\(\\mathbf L\\), and Runge-Lenz vector \\(\\boldsymbol\\epsilon\\). \\(E\\) is conserved when the potential \\(V\\) is time-invariant. \\(\\mathbf L\\) is conserved when \\(V\\) is central. \\(\\boldsymbol\\epsilon\\) is conserved when \\(V\\propto r^{-2}\\). Orbits of such potentials have conserved eccentricity. Reduce to planar motion using conservation of \\(\\mathbf L\\). Derive the orbit equations from conserved quantities. Analyze the different kinds of orbits by looking at the one-dimensional effective potential \\(V_{\\mathrm{eff}}\\). Analyze scattering. Problem setup Definition 1.1 (two-body problem) Consider two particles with mass \\(m_1, m_2\\) at locations \\(\\mathbf x_1, \\mathbf x_2 \\in \\mathbb R^3\\). Their potential is \\[ V(\\mathbf x_1, \\mathbf x_2) = -\\dfrac{k}{|\\mathbf x_1-\\mathbf x_2|} \\] Here \\(k\\in \\mathbb R\\) is a constant. The interaction is attractive when \\(k&gt;0\\) and repulsive when \\(k&lt;0\\). Computing the force based on the potential: \\[ \\mathbf F_j = -\\nabla_{\\mathbf x_j}V(\\mathbf x_1, \\mathbf x_2) = \\dfrac{k}{|\\mathbf x_1 - \\mathbf x_2|^2} \\nabla_{\\mathbf x_j}|\\mathbf x_1 - \\mathbf x_2| = \\dfrac{k}{|\\mathbf x_1-\\mathbf x_2|^2} \\begin{cases} (\\mathbf x_1 - \\mathbf x_2) &amp; j = 1 \\\\ (\\mathbf x_2 - \\mathbf x_1) &amp; j = 2 \\end{cases} \\tag{1.1} \\] Note that \\(\\mathbf F_1 + \\mathbf F_2 = 0\\). Recalling Newton’s second law, the equations of motion are \\[ \\ddot {\\mathbf x}_j = \\mathbf F_j / m_j \\] Instead of solving for \\(\\mathbf x_1, \\mathbf x_2\\), one can solve instead for the motion of the center of mass \\(\\mathbf R\\) and displacement \\(\\mathbf r\\). The motion of \\(\\mathbf R\\) will be trivial. Proposition 1.1 (center of mass motion) Define the center of mass \\[ \\mathbf R = \\dfrac{m_1}{m_1+m_2} \\mathbf x_1 + \\dfrac{m_2}{m_1+m_2}\\mathbf x_2 \\] The equation for the center of mass is \\[ (m_1+m_2)\\ddot {\\mathbf R} = m_1\\ddot{\\mathbf r}_1 + m_2\\ddot{\\mathbf r}_2 = \\mathbf F_1 + \\mathbf F_2 = 0 \\] The motion of the center of mass is thus completely determined by the initial conditions of the problem. Definition 1.2 (relative coordinates, displacement) Define the relative coordinates \\(\\mathbf r_j = \\mathbf x_j - \\mathbf R\\) and displacement \\(\\mathbf r = \\mathbf x_2 - \\mathbf x_1\\). Denote by \\(r=|\\mathbf r|, \\mathbf n = \\mathbf r / r\\). Note that \\(\\mathbf n\\) points in the direction \\(1\\to 2\\). Proposition 1.2 (one-body equation) The coordinates \\(\\mathbf r\\) obeys \\[ \\ddot {\\mathbf r} = \\mathbf F/\\mu, \\quad \\mathbf F = -\\nabla_{\\mathbf r} V(r) = -\\dfrac{k}{r^3} \\mathbf r \\quad \\mu = \\dfrac{m_1m_2}{m_1+m_2} \\] Here \\(\\mu\\) is the reduced mass which satisfies \\(1/m_1 + 1/m_2 = 1/\\mu\\). It is the “effective” mass of the one-body “particle” corresponding to the two-body problem. Additionally define the one-body momentum \\[ \\mathbf p = \\mu \\dot {\\mathbf r}, \\quad \\dot {\\mathbf p} = \\mathbf F \\] Proof: Rewriting (1.1) in terms of the newly defined quantities: \\[\\begin{align} m_1 \\ddot {\\mathbf x}_1 &amp;= \\dfrac{k}{r^2}\\mathbf n = -m_2 \\ddot {\\mathbf x}_2 \\\\ \\ddot {\\mathbf r} &amp;= \\ddot {\\mathbf x}_2 - \\ddot {\\mathbf x}_1 = -\\left(\\dfrac 1 {m_2} + \\dfrac 1 {m_1}\\right)\\dfrac{k}{r^2} \\mathbf n = - \\dfrac{k}{\\mu r^2}\\mathbf n \\end{align}\\] Three conserved quantities Definition 1.3 (conserved quantity (non-relativistic)) In Newtonian mechanics, a quantity is ‘’conserved’’ if it remains constant under time-evolution. Proposition 1.3 (conservation of energy) The energy scalar \\[ E = T + V = \\dfrac{\\mathbf p^2}{2\\mu} + V \\] is conserved by Newton’s equation of motion \\(\\mu \\ddot {\\mathbf r} = \\mathbf F = -\\nabla_{\\mathbf r} V(r)\\) Proof: Direct computation \\[ d_t E = d_t \\left( \\dfrac{\\mu^2 \\dot {\\mathbf r} \\cdot \\dot {\\mathbf r}}{2\\mu} + V \\right) = \\mu \\dot {\\mathbf r}\\cdot \\ddot {\\mathbf r} - (\\nabla_{\\mathbf r} V) \\cdot \\mathbf r = 0 \\] Note that \\(d_tV\\) is computed according to the dependence \\(V\\leftarrow \\mathbf r\\leftarrow t\\). Proposition 1.4 (conservation of angular momentum) The angular momentum vector \\[ \\mathbf L = \\mathbf r\\times \\mathbf p \\] Is conserved for any central force problem: one in which \\(V(\\mathbf r)=V(r, \\mathbf n) = V(r)\\) is only dependent on the magnitude, but not direction, of \\(r\\). Proof: Direct computation \\[ d_t \\mathbf L = d_t(\\mathbf r\\times \\mathbf p) = \\dot {\\mathbf r}\\times \\mathbf p + \\mathbf r \\times \\mathbf F = 0 + 0 \\] The first term vanishes by \\(\\mathbf p \\parallel \\dot {\\mathbf r}\\) and the second by the definition of central potential. Remark. This is our first example of symmetry-conservation. A central force problem demonstrates spherical symmetry. A rigorous definition of “symmetry” will be given soon. Proposition 1.5 (planar reduction) The trajectory \\(\\mathbf r\\) lie in the plane orthogonal to \\(\\mathbf L\\). Given this, let \\(\\mathbf n =\\mathbf r/r\\) be the first unit component of the plane and the second \\[ \\mathbf l = (\\mathbf L \\times \\mathbf r) / |\\mathbf L\\times \\mathbf r| \\] In polar coordinates, \\[ \\dot {\\mathbf r} = \\dot r \\mathbf n + r\\dot \\theta \\mathbf l \\implies \\mathbf L = \\mu r^2 \\dot \\theta (\\mathbf n\\times \\mathbf l) \\] Proof: \\(\\mathbf L = \\mu \\, \\mathbf r \\times \\dot {\\mathbf r}\\) is orthogonal to both \\(\\mathbf r\\) and \\(\\dot {\\mathbf r}\\), and \\(\\mathbf L\\) is conserved. Proposition 1.6 (conservation of the Runge-Lenz vector) The Runge-Lenz vector \\(\\boldsymbol\\epsilon\\) is defined as \\[ \\boldsymbol\\epsilon = \\dfrac 1 {\\mu k} \\mathbf p \\times \\mathbf L - \\mathbf n = \\dfrac 1 {\\mu k} [\\mathbf p \\times (\\mathbf r\\times \\mathbf p)] - \\mathbf n = \\dfrac 1 {\\mu k} [\\mathbf p \\times (\\mathbf r\\times \\mathbf p)] - \\mathbf n = \\dfrac{pL} {\\mu k} \\mathbf n - \\mathbf n \\] The vector is conserved. Proof: Direct computation. \\[\\begin{align} \\dot {\\boldsymbol\\epsilon} &amp;= \\dfrac 1 {\\mu k} \\mathbf F \\times \\mathbf L - \\dot {\\mathbf n} = \\dfrac 1 {\\mu k} \\left(-\\dfrac{k}{r^2} \\mathbf n\\right) \\times [\\mu r^2 \\dot \\theta (\\mathbf n \\times \\mathbf l)] - \\dot {\\mathbf n} \\\\ &amp;= -\\dot \\theta [\\mathbf n\\times (\\mathbf n \\times \\mathbf l)] - \\dot {\\mathbf n} = \\dot \\theta \\mathbf l - \\dot {\\mathbf n} = 0 \\end{align}\\] Proposition 1.7 (magnitude of the Runge-Lenz vector) The magnitude \\(\\epsilon = |\\boldsymbol\\epsilon|\\) is \\[ \\epsilon^2 = 1 + \\dfrac{2EL^2}{\\mu k^2} \\] Proof: First compute \\(\\mathbf p\\times \\mathbf L = \\mathbf p \\times (\\mathbf r \\times \\mathbf p) = Lp\\mathbf n\\). Then \\(\\mathbf n \\cdot (\\mathbf p\\times \\mathbf L) = Lp\\) and \\(|\\mathbf p\\times \\mathbf L|^2 = p^2L^2\\) since \\(\\mathbf p \\perp \\mathbf L\\). Also note that \\(p/L = 1/r\\), then then \\[\\begin{align} \\epsilon^2 &amp;= \\mathbf n\\cdot \\mathbf n + \\dfrac{1}{\\mu^2 k^2} [(\\mathbf p\\times \\mathbf L)\\cdot (\\mathbf p\\times \\mathbf L)] - \\dfrac{2}{\\mu k} \\mathbf n \\cdot (\\mathbf p\\times \\mathbf L) \\\\ &amp;= 1 + \\dfrac{p^2 L^2}{\\mu^2k^2} - 2 \\dfrac{pL}{\\mu k} = 1 + \\dfrac{2L^2}{\\mu k^2}\\left(\\dfrac{p^2}{2\\mu} - \\dfrac{pk}{L}\\right) = 1 + \\dfrac{2EL^2}{\\mu k^2} \\end{align}\\] Orbits, effective potential We can obtain an implicit equation of motion using the conservation equations. By definition of \\(\\boldsymbol\\epsilon\\) 1.6 \\[ \\mathbf r\\cdot \\boldsymbol\\epsilon = \\dfrac{rpL}{\\mu k} - r = \\dfrac{L^2}{\\mu k} - r \\] Let \\(\\mathbf r\\cdot \\boldsymbol\\epsilon = r\\epsilon \\cos\\theta\\), then the orbit equation reads \\[ r(1+\\cos\\theta) = \\dfrac{L^2}{\\mu k} \\tag{1.2} \\] Remark. Here the orientation is such that \\(\\theta=0\\) points along \\(\\boldsymbol\\epsilon\\). This is also an implicit orbit equation since time is not an explicit variable. The lecture note appendix works out the conic section trajectories corresponding to different ranges of \\(\\epsilon\\). Definition 1.4 (effective radial potential) So far, the kinetic energy is computed according to the vector derivative \\(\\dot {\\mathbf r}\\) \\[ E = T + V = \\dfrac 1 2 \\mu \\dot {\\mathbf r}^2 - \\dfrac{k}{r} \\] In our case, we can reduce this to a scalar problem by introducing the effective potential. Recall \\(\\dot {\\mathbf r} = \\dot (r\\mathbf n) = \\dot r\\mathbf n + r\\dot {\\mathbf n} = \\dot r\\mathbf n + r\\dot \\theta \\mathbf l \\implies \\dot {\\mathbf r}^2 = \\dot r^2 + r^2\\dot \\theta^2 = \\dot r^2 + L^2/\\mu^2 r^2\\) \\[ E = \\dfrac 1 2 \\mu \\dot{\\mathbf r}^2 - \\dfrac k r = \\dfrac 1 2 \\mu \\dot r^2 + \\left(\\dfrac{L^2}{2\\mu r^2} - \\dfrac k r \\right) \\] The last term in paranthesis is called the “effective potential \\(V_{\\mathrm{eff}}\\). Remark. Recall that \\(L\\) is conserved when the potential displays spherical symmetry. The effective potential conveniently reduces a vector problem into a scalar problem at the cost of introducing a “centrifugal” term. This is a prime example of symmetry helping simplify analysis. The effective potential reduction will show up again in the QM treatment of the hydrogen atom (Physics 143a) and spherical gravity correction (Physics 210). Energy is conserved along orbits, and we can easily identify the bound, unbound, and spherical orbits from the effective-potential graph. Exercise 1.1 (relativistic gravitational effective-potential) Identify the effective potential for Newtonian gravity, where \\(k=GM\\). What is the radius of the circular orbit? The effective radial potential from a spherical mass according to general relativity is \\[ V_{\\mathrm{eff}} = -\\sigma \\dfrac{GM}{r} + \\dfrac{L^2}{2r^2} - \\dfrac{GML^2}{r^3} \\] Where \\(\\sigma=0\\) if the particle is massless else \\(1\\). What are the behaviors for massive and massless particles? Scattering In scattering problems, we assume a spatially and temporally uniform distribution of incoming beams of particles along the incident \\(z\\)-axis. We use cylindrical coordinates \\((z, b, \\phi)\\) denoting height, radius, and the azimuthal angle, respectively. The main quantities are: Impact parameter \\(b\\), scattering angle \\(\\theta\\). Particles are incident within an infinitesimal patch with cross-sectional area \\(d\\sigma(b, \\phi) = b\\, db\\, d\\phi\\). Particle emission are considered according to a solid angle \\(d\\Omega(\\theta, \\phi) = \\sin\\theta \\, d\\theta\\, d\\varphi\\). The differential cross-section \\(d_\\Omega\\sigma \\equiv \\dfrac{b}{\\sin\\theta}|d_\\theta b|\\). Usually, the greater \\(\\theta\\) (heavier scattering effect), the smaller \\(b\\), since incident particles shoot closer to the scattering source – thus the absolute sign. The total cross-section \\(\\sigma = \\int (d_\\Omega \\sigma)\\, d\\Omega\\). This is the total cross-sectional area which encounters scattering. For classical hard-sphere scattering, this is \\(\\pi R^2\\). Remark. When the scattering source is spherically symmetric, all dependences on \\(\\phi\\) can be dropped. The differential cross-section \\(d_\\Omega \\sigma\\) asks: at angle \\(\\theta\\) from scattering center, what is the impact parameter \\(b\\) and how much unit increase in output solid angle will be able to account for unit area increase in the incident beams? To compute the two-body scattering differential cross-section, the first step is deriving the relation between the impact parameter \\(b\\) and scattering angle \\(\\theta\\). Proposition 1.8 (scattering relation) \\(b(\\theta) = \\dfrac{|k|}{2E} \\cot(\\theta/2)\\) Proof: Recall the orbit equation (1.2): denote the planar angle \\(\\phi\\), let \\(D = \\dfrac{L^2}{\\mu k}\\), and expand in terms of \\(x, y\\) \\[ r(1 + \\epsilon \\cos\\phi) = r + \\epsilon x = D \\] Expanding in terms of \\(x, y\\) \\[\\begin{align} r^2 &amp;= x^2 + y^2 = (D - \\epsilon x)^2 \\\\ y^2 &amp;= (\\epsilon^2 - 1)x^2 - 2D\\epsilon x + D^2 \\end{align}\\] For repulsive orbits, \\(\\epsilon&gt;1\\) and the orbits asymptote to \\[ y \\sim \\pm \\sqrt{\\epsilon^2 - 1} x, \\quad |x|\\to \\infty \\] The scattering angle \\(\\theta\\) in the scattering diagram thus satisfy \\[\\begin{align} \\tan\\theta_{\\mathrm{max}} = \\sqrt{\\epsilon^2 - 1}, \\quad \\tan(\\theta/2) = \\tan(\\pi/2 - \\theta_{\\mathrm{max}}) = \\cot(\\theta_{\\mathrm{max}}) \\end{align}\\] The angular momentum \\(L\\) of the incoming particle can be computed at the incident limit: \\[\\begin{align} L &amp;= |\\mathbf r\\times \\mathbf p| = b p = b\\sqrt{2\\mu E} \\\\ \\cot(\\theta/2) &amp;= \\tan(\\theta_{\\mathrm{max}}) = \\sqrt{\\dfrac{2EL^2}{\\mu k^2}} = \\dfrac{2bE}{|k|} \\end{align}\\] Theorem 1.1 (Rutherford cross-section formula) For repulsive two-body scattering, the cross-section is dependent upon \\(\\theta\\) as \\[ (d_\\Omega \\sigma)(\\theta) = \\left(\\dfrac{k}{4E}\\right)^2 \\sin^{-4}\\dfrac{\\theta}{2} \\] Proof: The first step is elucidating the dependence \\(d_\\Omega \\sigma \\leftarrow b,\\, d_\\theta b \\leftarrow \\theta\\). From 1.8 we have \\[\\begin{align} b(\\theta) &amp;= \\dfrac{|k|}{2E}\\cot(\\theta/2) \\\\ d_\\theta b &amp;= -\\dfrac{|k|}{4E} \\mathrm{csc}^2(\\theta/2) \\end{align}\\] Substituting into the relation \\(d_\\Omega \\sigma = b|d_\\theta b|/\\sin\\theta\\) yields formula as claimed. "],["lagranges-equations.html", "2 Lagrange’s Equations Covariant formulation Extremization formulation Representation perspective Separability of quadratic Lagrangians", " 2 Lagrange’s Equations In this section we develop two perspectives on Lagrange’s equations: A “covariant” formulation of Newton Cartesian equations. Equation of the trajectory satisfying the principle of least action. We note in the subfinal section that the two perspectives are related: the Euler-Lagrange vector \\(\\mathbb L_q\\) is (negative) the representing element of the directional derivative map \\(\\eta \\mapsto (D_\\eta \\mathcal S)(q)\\), which is a linear functional. Both perspectives are extremely important to the development of modern theoretical physics. Computationally, make sure to understand lemma 2.5, which also appears in the proof of Noether’s theorem. Covariant formulation Covariance: introduction What do we mean by something covariant? Consider a function \\(f:\\mathbb R^2\\to \\mathbb R\\) defined on the 2D plane according to \\[ f_1(x, y) = x^2+y^2 \\] This function is, in a sense, “equivalent” to the definition \\[ f_2(r, \\theta) = r^2 \\] Although \\(f_1, f_2\\) are defined on different domains, they represent the same function \\(f\\) defined on the \\(2D\\) plane: the choice of \\((x, y)\\) versus \\((r, \\theta)\\) are simply different choices of “charts” to represent the same underlying geometric object (manifold). When we specify \\(f(r, \\theta)=r^2\\) and understand \\((r, \\theta)\\) as a chart for \\(\\mathbb R^2\\), we have equivalently defined \\(f(x, y)=x^2+y^2\\). In this sense, \\(f\\) is covariant. Remark. Covariant objects are, in a sense, analogous to “platonic ideas.” Another prime example of a covariant object is an abstract linear transformation (e.g. rotation): in this case the matrix representations are obtained after fixing a chart (basis). Remark. If you want to dig deeper, study differential geometry! Euler-Lagrange Equations Let \\((q_j)=\\{q_1, \\cdots, q_N\\}\\) denote the degrees of freedom. A trajectory’s “snapshot” at a single time is completely captured by \\(((q_j), (\\dot q_j))\\). A Lagrangian is a scalar (function) which looks at such snapshots and evaluates to a number. Definition 2.1 (Lagrangian) The Lagrangian of a physical system is a map of type \\[ \\mathcal L: \\mathbb R^n\\times \\mathbb R^n \\times \\mathbb R\\to \\mathbb R \\] Its arguments are abbreviated \\(\\mathcal L(q, \\dot q, t)\\) but expands to \\[ \\mathcal L(q_1, \\cdots, q_n, \\dot q_1, \\cdots, \\dot q_n, t) \\] To be precise, the Lagrangian is a function on the tangent bundle \\(TM\\) of the configuration manifold \\(TM\\). Definition 2.2 (Euler-Lagrange Equations) According to the EL-equations, a trajectory \\(q(t)\\) is physical if \\[ 0 = \\mathbb L_q(t) = (d_t \\nabla_{\\dot q} - \\nabla_q)\\mathcal L(q, \\dot q, t) \\in \\mathbb R^n \\] for all \\(t\\). The notation above unpacks to \\(\\forall j=1, \\cdots, n\\). \\[ d_t (\\partial_{\\dot q_j} \\mathcal L) = \\partial_{q_j} \\mathcal L \\] the time-dependent Euler-Lagrange vector \\(\\mathbb L_q\\) captures the deviation from \\(0\\); we use the subscript to denote explicit dependence on the coordinates \\(q\\). In Cartesian coordinates, define the Newtonian Lagrangian to be \\[ \\mathcal L(x, \\dot x, t) = T - V = \\dfrac m 2 \\dot q^2 - V(q, t) \\] Then Lagrange’s equations (definition 2.2) simplify exactly to Newton’s equations. \\[ m\\ddot x = \\nabla_x V \\tag{2.1} \\] Covariance of Euler-Lagrange Equations The following theorem establishes that the following statements are equivalent: Newton’s equations (2.1) are true in Cartesian coordinates Lagrange’s equations are true in arbitrary invertible coordinates. Theorem 2.1 (Covariance of Euler-Lagrange equations) Given a coordinate transform \\(x\\to q\\), the EL-vector transforms covariantly according to \\[ \\mathbb L_q(t) = J_{q\\to x} \\mathbb L_x(t) \\] To prove this, we need to establish several lemmas. We begin by looking at how the change of coordinates \\(q\\to x\\) determines \\((q, \\dot q)\\to (x, \\dot x)\\). Lemma 2.1 (dot cancellation) \\(J_{\\dot q\\to \\dot x} = J_{q\\to x}\\). Proof: Follows from chain rule: \\[\\begin{align} \\dot x_j &amp;= d_t x_j(q_1, \\cdots, q_j) = (\\partial_{q_k} x_j) \\dot q_k \\implies \\dot x = J_{q\\to x} \\dot q \\end{align}\\] Now, \\(J_{q\\to x}\\) is independent of \\(\\dot q\\), so \\(J_{\\dot q\\to \\dot x} = J_{q\\to x}\\). Lemma 2.2 \\(J_{q\\to \\dot x} = d_t J_{q\\to x}\\) Proof: On the LHS, \\(\\partial_{q_i} \\dot x_j = \\partial_{q_i} (\\dot q_k \\partial_{q_k} x_j) = \\dot q_k (\\partial_{q_iq_k}^2 x_j)\\). On the RHS, \\((d_t J_{q\\to x}(q_1, \\cdots, q_n))_{ij} = (\\partial_{q_i q_k}^2 x_j) \\dot q_k\\). The next two lemmas essentially restate the chain rule for \\(q(x)\\) and \\(\\dot q(x, \\dot x)\\). Lemma 2.3 \\(\\nabla_{\\dot x} = J_{\\dot q\\to \\dot x} \\nabla_{\\dot q}\\). Lemma 2.4 \\(\\nabla_x = J_{\\dot q\\to x} \\nabla_q + J_{q\\to x}\\nabla_x\\). We are now ready to prove theorem 2.1 by expanding the operator \\(d_t\\nabla_{\\dot x} - \\nabla_x\\): \\[\\begin{align} d_t \\nabla_{\\dot x} - \\nabla_x &amp;= d_t (J_{\\dot q\\to \\dot x} \\nabla_{\\dot q}) - J_{q\\to x}\\nabla_q - J_{x\\to \\dot q}\\nabla_{\\dot q} \\\\ &amp;= (d_t J_{\\dot q\\to \\dot x})\\nabla_{\\dot q} + J_{\\dot q\\to \\dot x} d_t\\nabla_{\\dot q} - J_{q\\to x}\\nabla_q - J_{q\\to \\dot x}\\nabla_{\\dot q} \\\\ &amp;= (d_tJ_{x\\to q})\\nabla_{\\dot q} + J_{q\\to x} d_t\\nabla_{\\dot q} - J_{q\\to x}\\nabla_q - J_{q\\to \\dot x}\\nabla_{\\dot q} \\\\ &amp;= J_{q\\to \\dot x}\\nabla_{\\dot q} + J_{q\\to x} d_t\\nabla_{\\dot q} - J_{q\\to x}\\nabla_q - J_{q\\to \\dot x}\\nabla_{\\dot q} \\\\ &amp;= J_{q\\to x} d_t\\nabla_{\\dot q} - J_{q\\to x}\\nabla_q \\\\ &amp;= J_{q\\to x}(d_t \\nabla_{\\dot q} - \\nabla_q) \\end{align}\\] We applied lemmas 2.3 and 2.4 on line \\(1\\), applied the product rule to \\(J_{\\dot x\\to \\dot q}\\nabla_{\\dot q}\\) to obtain line \\(2\\) line \\(2\\), then cancelled the dots by lemma 2.1 to obtain line \\(3\\). Finally, we applied lemma 2.2 to line \\(3\\), cancelled terms, and regrouped. Constraints Sometimes it is convenient to consider an over-parameterized change of coordinates \\(x\\to q\\). In this case, \\(J_{q\\to x}\\) is “lean and tall”, while \\(J_{x\\to q}\\) “short and wide.” Recall the covariant formula \\[\\begin{align} \\mathbb L_x &amp;= J_{x\\to q} \\mathbb L_q \\end{align}\\] When \\(J_{x\\to q}\\) is full rank, the physicality condition \\[ \\mathbb L_x = 0 \\iff \\mathbb L_q=0 \\] When \\(q\\) is overparameterized, however, requiring \\(\\mathbb L_q=0\\) is too strong: the correct condition is \\[ \\mathbb L_x = 0 \\iff \\mathbb L_q\\in \\ker J_{x\\to q} \\] Consider a single constraint enforced by some constraint function \\(f(q)=0\\) of signature \\(f:\\mathbb R^n\\to \\mathbb R\\). Proposition 2.1 Given a constraint \\(f:\\mathbb R^N\\to \\mathbb R\\) and a trajectory \\(q(t)\\), if \\(f(q(t))=0\\) for all points on the trajectory, then \\[ \\nabla f \\in \\ker J_{x\\to q} \\] To be precise, the gradient \\((\\nabla f)(q(t))\\) evaluated at all points \\(q(t)\\) for all \\(t\\) is in the kernel of \\(J_{x\\to q}(q(t))\\) evaluated at \\(q(t)\\). Proof: Recognizing the chain rule: \\(J_{x\\to q} \\nabla\\big|_q f = J_{x\\to f}=0\\) since \\(f\\) is constant. Definition 2.3 (complete, independent constraints) Given an over-parameterized system with configuration in \\(\\mathbb R^{m&gt;n}\\), where there are only \\(n\\) true degrees of freedom, a set of constraints \\(\\{f_j:\\mathbb R^m\\to \\mathbb R\\}_{j=1}^k\\) is independent if for all possible configurations \\(q\\in \\mathbb R^m\\), the set of vectors \\[ C(q) = \\{\\nabla f_j\\big|_q\\}_{j=1}^k \\] are linearly independent. They are complete if \\(C(q)\\) spans \\(\\ker J_{x\\to q}(q)\\) for all points \\(q\\). All of this is a fancy way of saying that \\(f\\) is complete and independent iff they provide necessary and sufficient information to discern physicality \\(\\mathbb L_q\\in \\ker J_{x\\to q}\\). Given these constraints, \\(\\mathbb L_x=0\\) iff \\[\\begin{align} \\mathbb L_q(q, \\dot q) &amp;= \\sum_j \\lambda_j \\nabla_q f_j(q) \\in \\ker J_{x\\to q}, \\quad \\lambda_j \\in \\mathbb R\\\\ f_j(q) &amp;= 0 \\end{align}\\] This constrained problem can be solved by the standard Lagrange multiplier method. Extremization formulation In this subsection, we show that the Euler-Lagrange equations are fulfilled if and only if a certain action functional is extremized. This yields a powerful variational perspective on physicality. Definition 2.4 (action functional) Given a Lagrangian \\(\\mathcal L(q, \\dot q, t)\\) (definition 2.1), its associated action functional \\(\\mathcal S_{[a, b]}(p)\\) takes in \\(3\\) arguments: Begining time \\(a\\in \\mathbb R\\). End time \\(b\\in \\mathbb R\\). A path \\(q:[a, b]\\to \\mathbb R^n\\). and outputs the scalar \\[ \\mathcal S_{[a, b]}(p) = \\int_a^b \\mathcal L(q(t), \\dot q(t), t)\\, dt \\] To properly define extremization, we need the directional derivative. Fixing \\(a, b\\), the directional derivative \\((D_\\eta \\mathcal S_{[a, b]})(q)\\) tells us how much \\(\\mathcal S(q)\\) changes if we nudge \\(q\\) in the direction of \\(\\eta\\) infinitesimally. Definition 2.5 (directional derivative of action) Fixing \\(a, b\\), the directional derivative \\((D_\\eta \\mathcal S_{[a, b]})(q)\\) takes in two arguments: The perturbing path \\(\\eta: [a, b]\\to \\mathbb R^n\\). The path at which the perturbation is evaluated \\(q:[a, b]\\to \\mathbb R^n\\). and outputs the scalar slope of \\(\\mathcal S_{[a, b]}(q+\\epsilon \\eta)\\) w.r.t \\(\\epsilon\\), evaluated at \\(0\\): \\[ (D_\\eta \\mathcal S_{[a, b]})(q) = \\lim_{\\epsilon \\to 0} \\dfrac{\\mathcal S_{[a, b]}(q) + \\mathcal S_{[a, b]}(q+\\epsilon \\eta)}{\\epsilon} \\] To reduce notation clutter, we abbreviate this as \\[ D_\\eta S(q) = d_\\epsilon \\big|_0 S(q+\\epsilon \\eta) \\] The magic in the air is that the Euler-Lagrange vector (definition 2.2) \\(\\mathbb L_q\\) gives us the directional derivative when the input perturbation is endpoint-preserving. Theorem 2.2 (endpoint-preserving derivative) For endpoint-preserving \\(\\eta:[a, b]\\to \\mathbb R\\) such that \\(\\eta(a)=\\eta(b)=0\\), the directional derivative of \\(\\mathcal S\\) is given by \\[ (D_\\eta \\mathcal S)(q) = -\\int_a^b \\mathbb L_q(t) \\eta(t)\\, dt \\] Proof: Fixing \\(q, \\eta\\), for any \\(\\epsilon&gt;0\\) let \\(q_\\epsilon:[a, b]\\to \\mathbb R^n\\) denote the family of paths given by \\[ q_\\epsilon(t) = q(t) + \\epsilon \\eta(t) \\tag{2.2} \\] Slide \\(d_\\epsilon\\) into the integral and apply lemma 2.5, then apply the endpoint-vanishing condition \\[\\begin{align} (D_\\eta \\mathcal S)(q) &amp;= d_\\epsilon \\big|_{\\epsilon=0} \\mathcal S(q+\\epsilon \\eta) = \\int_a^b d_\\epsilon \\mathcal L(q_\\epsilon, \\dot q_\\epsilon, t)\\, dt \\\\ &amp;= \\int_a^b \\left[ -\\eta \\cdot \\mathbb L_q + d_t \\left(\\eta \\cdot \\nabla_{\\dot q}\\mathcal L\\right) \\right]\\, dt \\\\ &amp;= \\left(\\eta \\cdot \\nabla_{\\dot q}\\mathcal L\\right)\\big|^b_a -\\int_a^b \\eta \\cdot \\mathbb L_q\\, dt = -\\int_a^b \\eta \\cdot \\mathbb L_q\\, dt \\end{align}\\] The following lemma is the key component in the calculus of variations. Make sure to read it carefully. Lemma 2.5 (ε-derivative of the perturbed Lagrangian) With \\(q_\\epsilon=q + \\epsilon \\eta\\) as in (2.2) \\[ d_\\epsilon \\mathcal L(q_\\epsilon, \\dot q_\\epsilon) = -\\eta \\cdot \\mathbb L_q + d_t \\left(\\eta \\cdot \\nabla_{\\dot q}\\mathcal L\\right) \\] Proof: Using the dependence \\(\\epsilon \\to (q_\\epsilon, \\dot q_\\epsilon) \\to \\mathcal L\\), apply the chain rule \\[\\begin{align} d_\\epsilon \\mathcal L(q_\\epsilon, \\dot q_\\epsilon) &amp;= (d_\\epsilon q_\\epsilon) \\cdot (\\nabla_q \\mathcal L) + (d_\\epsilon \\dot q_\\epsilon) \\cdot (\\nabla_{\\dot q} \\mathcal L) \\\\ &amp;= \\eta \\cdot \\nabla_q \\mathcal L + d_t \\eta \\cdot \\nabla_{\\dot q} \\mathcal L \\\\ &amp;= \\eta \\cdot \\nabla_q \\mathcal L + d_t \\left(\\eta \\cdot \\nabla_{\\dot q}\\mathcal L \\right) - \\eta \\cdot d_t \\nabla_{\\dot q}\\mathcal L \\\\ &amp;= \\eta \\cdot (\\nabla_q - d_t \\nabla_{\\dot q})\\mathcal L + d_t \\left(\\eta \\cdot \\nabla_{\\dot q} \\mathcal L\\right)\\\\ &amp;= -\\eta \\cdot \\mathbb L_q + d_t \\left(\\eta \\cdot \\nabla_{\\dot q}\\mathcal L\\right) \\end{align}\\] On the second line, we used integration by parts on the time-derivative to transfer the time-derivative on \\(\\eta\\) (which we don’t like) to \\(\\nabla_{\\dot q}\\mathcal L\\) (which we like, since it appears in \\(\\mathbb L_q\\)). It is a standard result in real analysis (fundamental lemma of the calculus of variations) that for \\[ (D_\\eta \\mathcal S)(q) = -\\int_a^b \\mathbb L_q(t) \\eta(t)\\, dt \\] to be \\(0\\) for all reasonable endpoint-preserving perturbations \\(\\eta\\) (which includes, in particular, compactly supported smoth functions), \\(\\mathbb L_q(t)\\) must be \\(0\\). This allows us to prove another equivalence result. Theorem 2.3 (Hamilton's principle) Recall that, given a Lagrangian \\(\\mathcal L(q, \\dot q, \\epsilon)\\), we call a path \\(q:[a, b]\\to \\mathbb R^n\\) physical iff \\[ \\mathbb L_q(t)=0, \\quad t\\in [a, b], \\quad \\mathbb L_q(t) = (d_t \\nabla_{\\dot q} - \\nabla_q) \\mathcal L(q(t), \\dot q(t), t) \\] Then a path \\(q\\) is physical iff it extremizes the action functional at \\(\\mathcal S_{[a, b]}(q)\\) (definition 2.4) w.r.t all endpoint-preserving perturbations \\(\\eta:[a, b]\\to \\mathbb R^n, \\eta(a)=\\eta(b)=0\\) \\[ (D_\\eta \\mathcal S)(q) = 0 \\] Representation perspective In this section we give some intuition to the equation \\[ (D_\\eta \\mathcal S)(q) = -\\langle\\mathbb L_q, \\eta\\rangle, \\quad \\langle f, g\\rangle= \\int_a^b f(t)g(t)\\, dt \\tag{2.3} \\] To motivate this, consider a finite-dimensional real vector space \\(V\\) equipped with an inner product \\(\\langle a, b\\rangle\\). A (real) linear functional \\(\\alpha\\) on the space of \\(V\\) is a function of the signature \\(\\alpha:V\\to \\mathbb R\\) satisfying linearity: \\[ \\alpha(u + c v) = \\alpha(u) + c\\alpha(v), \\quad \\forall u, v\\in V, \\quad c\\in \\mathbb R \\] Some thought shows that every linear functional is uniquely specified by another vector \\(a\\in V\\) according to \\(\\alpha(v) = \\langle a, v\\rangle\\). Fix any basis \\(\\{b_1, \\cdots b_n\\}\\), given \\(\\alpha:V\\to \\mathbb R\\) we let \\[ a = \\sum_{j=1}^n \\alpha(b_j) b_j \\implies \\langle a, \\sum_{j=1}^N c_j b_j\\rangle= \\sum c_j \\alpha(b_j) = \\alpha\\left( \\sum_{j=1}^N c_j b_j \\right) \\] Fixing an interval \\(a, b\\) and classical trajectory \\(q\\) on \\(a, b\\), note the following facts: the set of all endpoint-preserving perturbations \\(\\eta:[a, b]\\to \\mathbb R^n\\) form a vector space \\(V\\). The map \\(\\eta\\mapsto (D_\\eta \\mathcal S)(q)\\) is a linear functional w.r.t. \\(\\eta\\): this is the main content of theorem 2.2. With regards to our previous discussion, theorem 2.2 equivalently states that we can regard \\[ -\\mathbb L_q = (\\nabla_q - d_t \\nabla_{\\dot q})\\mathcal L(q, \\dot q) \\] as the representation of the linear functional \\(\\eta \\mapsto (D_\\eta \\mathcal S)(q)\\), just as how \\(a\\in V\\) represents \\(\\alpha:V\\to \\mathbb R\\). Separability of quadratic Lagrangians The following result is also used in the path integral formulation of quantum mechanics. Proposition 2.2 (Actions of quadratic Lagrangians are separable about the classical trajectory) Given a quadratic Lagrangian \\[ \\mathcal L(q, \\dot q) = u\\, \\dot q^2 + v\\, q^2 \\] for path \\(q\\) wich satisfies the Euler-Lagrange equations, the Lagrangian satisfies \\[ \\mathcal L(q+\\eta, \\dot q + \\dot \\eta) = \\mathcal L(q, \\dot q) + \\mathcal L(\\eta, \\dot \\eta) = \\mathcal L(q, \\dot q) + \\epsilon \\mathcal L(\\eta, \\dot \\eta) + d_t \\left[\\eta \\cdot \\nabla_{\\dot q}\\mathcal L(q, \\dot q)\\right] \\] In particular, if the perturbation \\(\\eta:[a, b]\\to \\mathbb R^n\\) is additionally endpoint preserving so \\(\\eta(a)=\\eta(b)=0\\), then \\[ \\mathcal S(q+\\eta) = \\mathcal S(q)+\\mathcal S(\\eta) \\] Proof: Consider the function in \\(\\epsilon:\\mathbb R\\to \\mathbb R\\) defined by \\[\\begin{align} \\mathcal L(\\epsilon) &amp;= \\mathcal L(q + \\epsilon \\eta, \\dot q + \\epsilon \\dot \\eta) = u (\\dot q + \\epsilon \\dot \\eta)^2 + v(q + \\epsilon \\eta)^2 \\\\ \\end{align}\\] It helps at this point to compute some of its derivatives \\[\\begin{align} \\eta \\cdot \\nabla_q \\mathcal L &amp;= \\eta \\cdot 2v\\epsilon (q + \\epsilon \\eta), \\quad \\eta \\cdot \\nabla_{\\dot q} \\mathcal L = \\dot \\eta \\cdot 2u\\epsilon (\\dot q + \\epsilon \\dot \\eta) \\\\ \\dfrac 1 2 (\\eta \\cdot \\nabla_q)^2 \\mathcal L &amp;= (\\eta \\cdot \\nabla_q)\\left[ \\eta \\cdot 2v\\epsilon (q + \\epsilon \\eta) \\right] = \\epsilon v \\, \\eta^2 \\\\ \\dfrac 1 2 (\\eta \\cdot \\nabla_{\\dot q})^2 \\mathcal L &amp;= (\\dot \\eta \\cdot \\nabla_{\\dot q}) \\left[\\dot \\eta \\cdot 2u\\epsilon (\\dot q + \\epsilon \\dot \\eta) \\right] = \\epsilon u \\, \\dot \\eta^2 \\\\ [(\\nabla \\cdot \\nabla_q)(\\dot \\eta \\cdot \\nabla_{\\dot q})] \\mathcal L &amp;= [(\\dot \\eta \\cdot \\nabla_{\\dot q})(\\nabla \\cdot \\nabla_q)] \\mathcal L = 0 \\\\ \\dfrac 1 2 (\\eta \\cdot \\nabla_q + \\dot \\eta \\cdot \\nabla_{\\dot q})^2 \\mathcal L(\\epsilon) &amp;= \\epsilon \\mathcal L(\\eta, \\dot \\eta) \\end{align}\\] Taylor expanding about \\(\\epsilon=0\\) yields \\[\\begin{align} \\mathcal L(q + \\epsilon \\eta, \\dot q + \\epsilon \\dot \\eta) &amp;= \\mathcal L(q, \\dot q) + \\sum_{k=1}^\\infty \\dfrac{ (\\eta \\cdot \\nabla_q + \\dot \\eta \\cdot \\nabla_{\\dot q})^k } {k!} \\mathcal L(q + \\epsilon \\eta, \\dot q + \\epsilon \\dot \\eta) \\\\ &amp;= \\mathcal L(0) + (\\eta \\cdot \\nabla_q + \\dot \\eta \\cdot \\nabla_{\\dot q}) \\mathcal L + \\dfrac 1 2 (\\eta \\cdot \\nabla_q + \\dot \\eta \\cdot \\nabla_{\\dot q})^2 \\mathcal L \\\\ &amp;= \\mathcal L(q, \\dot q) + \\epsilon \\mathcal L(\\eta, \\dot \\eta) + (\\eta \\cdot \\nabla_q + \\dot \\eta \\cdot \\nabla_{\\dot q}) \\mathcal L \\tag{2.4} \\end{align}\\] We will now show that the extra last term (which came from the linear expansion) is zero when \\(\\eta\\) is time-dependent. We do this by using the product rule and the condition that at \\(\\epsilon=0\\), the path satisfies the Euler-Lagrange equation \\[\\begin{align} (\\eta \\cdot \\nabla_q + \\dot \\eta \\cdot \\nabla_{\\dot q})\\mathcal L &amp;= [\\eta \\cdot \\nabla_q + d_t(\\eta \\cdot \\nabla_{\\dot q}) - \\eta \\cdot d_t \\nabla_{\\dot q}] \\mathcal L \\\\ &amp;= d_t(\\eta \\cdot \\nabla_{\\dot q})\\mathcal L \\end{align}\\] Where we recognized \\(\\eta \\cdot \\nabla_q - \\eta \\cdot (d_t\\nabla_{\\dot q})\\mathcal L = -\\eta \\cdot \\mathbb L = 0\\). Substituting back into equation (2.4) \\[ \\mathcal L(q + \\epsilon \\eta, \\dot q + \\epsilon \\dot \\eta) = \\mathcal L(q, \\dot q) + \\epsilon \\mathcal L(\\eta, \\dot \\eta) + d_t \\left[\\eta \\cdot \\nabla_{\\dot q}\\mathcal L(q, \\dot q)\\right] \\] Substitute \\(\\epsilon=1\\) and integrate to obtain the action. The last total-derivative term vanishes by endpoint-preserving property of \\(\\eta\\). "],["noethers-theorem.html", "3 Noether’s theorem", " 3 Noether’s theorem Noether’s theorem elucidates how continuous symmetries result in conserved quantities; the converse will be provided by Hamiltonian mechanics. The key points in this section are: The definition of a continuous symmetry. Noether’s theorem. The conserved-quantity when \\(\\mathcal L\\) is time-invariant: the Hamiltonian. It’s convenient to now define a quantity we’ll be using later very often: Definition 3.1 (canonical momentum) Given the Lagrangian \\(\\mathcal L(q, \\dot q, t)\\) of a system, its canonical momentum is \\[ p = \\nabla_{\\dot q} \\mathcal L(q, \\dot q, t) \\] In terms of the canonical momentum, the Euler-Lagrange equations read \\[ \\mathbb L_q = \\dot p - \\nabla_q \\mathcal L = 0 \\] We will make extensive use of lemma 2.5, which we state here again using the canonical momentum for convenience: Lemma 3.1 (ε-derivative of the perturbed Lagrangian) Given a path \\(q:[a, b]\\to \\mathbb R\\) and a perturbation path \\(\\eta:[a, b]\\to \\mathbb R\\), define the parameterized family of paths \\(q_\\epsilon=q + \\epsilon \\eta\\), then \\[ d_\\epsilon \\mathcal L(q_\\epsilon, \\dot q_\\epsilon) = -\\eta \\cdot \\mathbb L_q + d_t \\left(\\eta \\cdot p\\right) \\] Definition 3.2 (continuous symmetry) Consider a family of maps \\(q_\\epsilon\\) such that \\(q_0\\) is the classical trajectory w.r.t. the Lagrangian \\(\\mathcal L\\). Define \\[ \\mathcal L_\\epsilon = \\mathcal L(q_\\epsilon, \\dot q_\\epsilon, t) \\] as well as the parameterized action function \\[ S_\\epsilon = \\int_a^b \\mathcal L(q_\\epsilon, \\dot q_\\epsilon, t)\\, dt \\] The physical system has continuous symmetry under the transformation parameterized by \\(q\\mapsto q_\\epsilon\\) if \\[ d_\\epsilon \\big|_0 S_\\epsilon = C \\] where \\(C\\) is a constant independent of the dynamical variables \\(q, \\dot q, t\\). In other words, infinitesimal reparameterization by \\(\\epsilon\\) leaves the equations of motion unchanged. Proposition 3.1 (characterization of continuous symmetry via Lagrangian) \\(\\epsilon \\mapsto q_\\epsilon\\) is a continuous symmetry if \\[ d_\\epsilon \\big|_0 \\mathcal L_\\epsilon = d_t F(q, \\dot q, t) \\] Note that the right-hand side must be a total time derivative. Proof: Direct computation: \\[ d_\\epsilon \\big|_0 S_\\epsilon = \\int_a^b d_\\epsilon \\big|_0 \\mathcal L_\\epsilon \\, dt = \\int_a^b d_t(F) \\, dt = F(b)-F(a) \\] Theorem 3.1 (Noether's theorem) Given a continuous symmetry \\(q_\\epsilon\\) such that \\[ d_\\epsilon \\big|_0 \\mathcal L(q_\\epsilon, \\dot q_\\epsilon, t) = d_t F(q, \\dot q, t) \\] The following Noether change is conserved along a classical trajectory obeying the Euler-Lagrange equations \\[ Q = \\left(d_\\epsilon \\big|_0 q_\\epsilon \\right) \\cdot \\nabla_{\\dot q}\\mathcal L(q, \\dot q, t) - F(q, \\dot q, t) \\] Let \\(q_\\epsilon = q + \\epsilon \\eta\\) for small \\(\\epsilon\\) (this is effectively adapting vector field perspective), the Noether charge is \\[ Q = \\eta \\cdot p - F(q, \\dot q, t) \\] One special case is for \\(F\\) to vanish, in which case \\[ d_\\epsilon \\big|_0 \\mathcal L(q_\\epsilon, \\dot q_\\epsilon, t) = 0 \\implies Q = \\eta \\cdot p \\text{ conserved.} \\] Proof: Direct computation invoking lemma 3.1: the \\(\\mathbb L_q\\) term vanishes on the classical trajectory \\[\\begin{align} d_t F &amp;= d_\\epsilon \\big|_0 \\mathcal L(q_\\epsilon, \\dot q_\\epsilon) = - \\eta \\cdot \\mathbb L_q + d_t(\\eta \\cdot p) = d_t(\\eta \\cdot p) \\end{align}\\] This implies that the time-derivative of the Noether charge is \\(0\\). Proposition 3.2 (conservation of energy) Let \\(\\mathcal L\\) be independent of time and denote the time-translation transform \\[ q_\\epsilon(t) = q(t+\\epsilon) \\] This is a continuous symmetry with \\(F(q, \\dot q) = \\mathcal L(q, \\dot q)\\) \\[ d_\\epsilon \\big|_0 \\mathcal L(q_\\epsilon, \\dot q_\\epsilon) = d_t \\mathcal L \\] The associated \\(\\eta = d_\\epsilon \\big|_0 q_\\epsilon = d_\\epsilon \\big|_0 q(t+\\epsilon) = \\dot q\\). Substituting into Noether’s theorem yields the conserved quantity \\[ H = \\dot q\\cdot p - \\mathcal L(q, \\dot q) \\] "],["hamiltonian-mechanics.html", "4 Hamiltonian Mechanics Legendre transform Hamilton’s equations", " 4 Hamiltonian Mechanics We begin by enumerating three properties of the Legendre transform, which relates (convex) Lagrangians and Hamiltonians. Key takeaways of this part are: The Hamiltonian \\(H(q, p, t)\\) is the Legendre transform of \\(\\mathcal L(q, \\dot q, t)\\) fixing \\(q, t\\). Fixing \\(q, t\\), the conjugate variables \\(\\dot q\\) and \\(p\\) are functions of each other by \\(\\nabla_{\\dot q} \\mathcal L = p\\) and \\(\\dot q = \\nabla_p H\\) (lemma 4.1). The Jacobian \\(J_{p\\to q}\\) is the Hessian. When the \\(\\sup\\) is dropped in the Legendre transform, the two variables are always understood to obey an implicit equation. On strictly convex functions, the Legendre transform preserves convexity, and is involutary. Legendre transform The Legendre transform is a general transform of functions which interactive particularly well with convex functions. Definition 4.1 (Legendre transform) Given a function \\(f:\\mathbb R^n\\to \\mathbb R\\), its Legendre transform \\(\\mathbb L f: \\mathbb R^n\\to \\mathbb R\\) is \\[ (\\mathbb L f)(p) = \\sup_x \\, \\langle x, p\\rangle- f(x) \\] Convex functions Convex functions are characterized by \\[ f(\\lambda x + \\bar \\lambda y) \\leq \\lambda f(x) + \\bar \\lambda f(y), \\quad \\lambda \\in [0, 1], \\bar \\lambda = 1 - \\lambda \\] assume they’re well-behaved enough, they’re equivalently defined by having positive (semi) definite second-derivatives (Hessian) at all points: \\[ (\\mathcal H_x f)(\\forall x) \\geq 0, \\quad (\\mathcal H_x f)_{ij}(x) = (\\partial_{x_i x_j}^2 f)(x) \\] Here \\(A\\geq 0\\) for matrix \\(A\\) is understood as all eigenvalues of \\(A\\) being nonnegative. Convexity is further equivalent to \\[ \\forall x, y: f(y) \\geq \\nabla f(x) \\cdot (y - x) \\] The function \\(f\\) is strictly convex when the inequalities are strict. Proposition 4.1 The gradient map \\(x\\mapsto (\\nabla f)(x)\\) is invertible if \\(f\\) is strictly convex. Proof: For \\(x\\neq y\\), strict convexity implies \\[\\begin{align} \\nabla f(x) \\cdot (y-x) &lt; f(y) - f(x), \\quad \\nabla f(y) \\cdot (x-y) &lt; f(x) - f(y) \\end{align}\\] Suppose for contradiction that \\(\\nabla f(x) = \\nabla f(y)\\), substituting \\(\\nabla f(y)=\\nabla f(x)\\) in the last equation and multiplying both sides by \\(-1\\) yields the contradiction \\[ \\nabla f(x) (y-x) &gt; f(y) - f(x) \\] Properties of the Legendre transform We now show that the Legendre transform is well-behaved for strictly convex functions. Assuming \\(f\\) well-behaved, the extremality condition is \\[ \\nabla_x \\langle x, p\\rangle- f(x) = p - \\nabla_x f(x) = 0 \\iff p = \\nabla_x f \\] This means that the \\(\\sup\\) may be dropped when it is understood that \\(x\\) is an implict function of \\(p\\) via the equation \\(p = \\nabla_x f\\) : \\[ (\\mathbb L f)(p=\\nabla_x f) = x\\cdot p - f(x) \\] The following lemma will prove the Hamilton equation \\(\\dot q = \\nabla_p H\\). Lemma 4.1 (two-way relation between x and p) Given a Legendre transform \\[ g(p) = (\\mathbb L f)(p) = \\sup_x p\\cdot x - f(x) \\] Then \\(p = \\nabla_x f \\iff x = \\nabla_p g\\). Proof: Assuming \\(p = \\nabla_x f\\), then we can drop the \\(\\sup\\) in the Legendre transform, yielding \\[ g(p) = p\\cdot x - f(x) \\] Take the gradient w.r.t. \\(p\\) on both sides; note that we need to invoke the chain rule since \\(p, x\\) are related: \\[\\begin{align} \\nabla_p g(p) &amp;= \\nabla_p (p\\cdot x - f(x)) = x + J_{p\\to x} p - J_{p\\to x} (\\nabla_x f)_{=p} = x \\end{align}\\] Proposition 4.2 (Jacobian of Legendre transform) The Jacobian of the Legendre transform \\(x\\to p\\) is the Hessian of \\(f\\) \\[ J_{x\\to p} = d_x p = d_x \\left(\\nabla_x f\\right) = \\mathcal H_x f \\] Proposition 4.3 (convexity invariance) Suppose \\(f(x)\\) is convex strictly convex so \\(\\mathcal H_x f&gt; 0\\) (positive-definite) everywhere, then \\(\\mathbb L f\\) is convex, i.e. \\(\\mathcal H_p (\\mathbb L f)&gt;0\\). Proof: Computing the Hessian explicitly and recognize \\(\\nabla_x f = p\\) \\[\\begin{align} \\mathcal H_p(\\mathbb L f) &amp;= d_p [\\nabla_p (\\mathbb L f)] = d_p \\left[ x + J_{p\\to x} p - J_{p\\to x}\\nabla_x f \\right] \\\\ &amp;= d_p x = J_{p\\to x} = J_{x\\to p}^{-1} = \\left(\\mathcal H_x f\\right)^{-1} \\end{align}\\] Convexity follows from the convexity of \\(\\mathcal H_x f&gt; 0\\). Proposition 4.4 (involutary) For convex \\(f\\), the Legendre transform is involutary \\[ \\mathbb L \\left[(\\mathbb L f)(p)\\right] (x) = f(x) \\] Proof: Unroll the definition \\[\\begin{align} \\mathbb L \\left[(\\mathbb L f)(p)\\right] (x) &amp;= \\mathbb L \\left[p\\mapsto xp - f(x)\\right] (x)\\\\ &amp;= xp - \\left[p\\mapsto xp - f(x)\\right]\\, p = xp - xp - f(x) = f(x) \\end{align}\\] Note the dependence here: fixing \\(x\\), we can fix \\(p=\\nabla_x f\\), which in turn determines \\(x\\) in the inner Legendre transform. Hamilton’s equations Definition 4.2 (Hamiltonian) Given the Lagrangian \\(\\mathcal L(q, \\dot q, t)\\), the Hamiltonian is the Legendre transform of \\(\\dot q\\mapsto p\\) holding \\(q\\) fixed \\[ H(q, p, t) = p\\cdot \\dot q - \\mathcal L(q, \\dot q(p), t) \\] where \\(p = \\nabla_{\\dot q} \\mathcal L\\) and \\(\\dot q(p)\\) is the implicit inverse of this equation. Theorem 4.1 (Hamilton's equations) The following equations are equivalent to the Euler-Lagrange equations 2.2 when the Lagrangian \\(\\mathcal L(q, \\dot q, t)\\) is strictly convex in in \\(\\dot q\\): \\[\\begin{aligned} \\dot p = -\\nabla_q H, \\quad \\dot q = \\nabla_p H \\end{aligned}\\] Collecting \\(\\xi = q \\oplus p\\) and write \\(H(q, p, t) = H(\\xi, t)\\), we have the compact expression \\[ \\partial_{t} \\xi = \\Gamma\\, \\nabla_\\xi H, \\quad \\Gamma = \\bigoplus \\begin{pmatrix} 0 &amp; 1 \\\\ -1 &amp; 0 \\end{pmatrix} \\] Proof: Take care that \\(\\dot q, p\\) are implicit functions of each other and recognize \\(p=\\nabla_{\\dot q}\\mathcal L\\); holding \\(q\\) fixed: \\[\\begin{align} \\nabla_p H(q, p, t) &amp;= \\nabla_p \\left[p\\cdot \\dot q - \\mathcal L(q, \\dot q(p), t)\\right] \\\\ &amp;= \\dot q + J_{p\\to \\dot q} p - J_{p\\to \\dot q}(\\nabla_{\\dot q}\\mathcal L) = \\dot q \\end{align}\\] For the second equation, we’re holding \\(p\\) fixed, but \\(\\dot q\\) is still dependent upon \\(q\\), then \\[\\begin{align} \\nabla_q H(q, p, t) &amp;= \\nabla_q \\left[ p\\cdot \\dot q - \\mathcal L(q, \\dot q(p), t) \\right] \\\\ &amp;= J_{q\\to \\dot q}p - \\nabla_q \\mathcal L - J_{q\\to \\dot q} (\\nabla_{\\dot q}\\mathcal L) = - \\nabla_q \\mathcal L \\\\ \\dot p &amp;= d_t \\nabla_{\\dot q}\\mathcal L = \\nabla_q \\mathcal L \\end{align}\\] the last equation holds by the Euler-Lagrange equations. Remark. For those interested in differential geometry, Hamilton’s equations \\(\\partial_{t} \\xi = \\Gamma \\, \\nabla_\\xi H\\) is the component representation of the following implicit equation which defines the vector field \\(X_H\\) generating the time-translation of the system: \\[ \\omega(X_H, \\, \\cdot\\, ) = dH \\] Here \\(\\omega= dq \\wedge dp\\) is the symplectic form represented by \\(\\Gamma\\), and \\(dH\\) is the differential of \\(H\\). optional material: relation between implicit and coordinate equation Given a chart \\(x=(x_1, \\cdots, x_n)\\) on a manifold \\(M\\) (like fixing a basis), a vector field \\(X\\) can be understood as a directional derivative operation that consumes a scalar function \\(f\\) and outputs \\(X\\, f\\) (read as \\(X\\) acting on \\(f\\). The value of \\((X\\, f)(x)\\) encodes how much \\(f\\) changes along the direction of \\(X\\) at location \\(x\\). The representation of \\(X\\) in this chart \\(x\\) is then \\[ X = \\sum_{j=1}^n X_j \\partial_{j} \\] where each \\(X_j\\) is a scalar function; in this representation, the action can be easily understood as \\[ (X\\, f)(x) = \\sum_{j=1}^n X_j \\partial_{j} f(x) = (X_j)\\cdot \\nabla f(x) \\] where \\((X_j)\\) is understood as a vector denoting the ``direction’’; in this sense the chart \\(x\\) also fixes a basis \\(\\partial_{1}, \\cdots \\partial_{n}\\) for the space of vector fields (tangent bundle). Given a scalar function \\(f\\), its differential \\(df\\) eats a vector field and outputs a scalar (function) \\[ df\\, X = X\\, f \\] We can similarly consider a basis representation for the differentials (which live on the cotangent bundle) with the notation \\(d x_1, \\cdots, dx_n\\) \\[ df = \\sum_{j=1}^N f_j dx_j, \\quad dx_j\\, \\partial_{i} = \\delta_{ij} \\] The last piece we need is the wedge product: assuming a basis \\(B=\\{\\partial_{p}, \\partial_{q}\\}\\) (\\(p\\), \\(q\\) are univariables), the symplectic form \\(\\omega = dq \\wedge dp\\) consumes two arguments in \\(B\\) and outputs a number subject to the following rules: \\[ (dq \\wedge dp)(\\partial_{a}, \\partial_{b}) = \\begin{cases} 1 &amp; (\\partial_{a}, \\partial_{b}) = \\partial_{q}, \\partial_{p} \\\\ -1 &amp; (\\partial_{a}, \\partial_{b}) = \\partial_{p}, \\partial_{q} \\\\ 0 &amp; \\text{otherwise}. \\end{cases} \\] and being linear in each of its arguments. Back to Hamilton’s equation \\(\\omega(X_H, \\cdot) = dH\\). Fix the basis \\(\\{\\partial_{q}, \\partial_{p}\\}\\) (the order matters!) and consider two vector fields \\[ X = X_q \\partial_{q} + X_p \\partial_{p}, \\quad Y = Y_q \\partial_{q} + Y_p \\partial_{p} \\] The representation \\(\\Gamma\\) of \\(\\omega\\) is read from the equation \\[\\begin{align} \\omega(X, Y) &amp;= X_qY_q \\omega(\\partial_{q}, \\partial_{q})_{=0} + X_p Y_q \\omega(\\partial_{p}, \\partial_{q})_{=-1} + X_qY_p \\omega (\\partial_{q}, \\partial_{p})_{=1} + X_pY_p \\omega (\\partial_{p}, \\partial_{p})_{=0} \\\\ &amp;= X_qY_p - X_p Y_q = \\begin{pmatrix} X_q \\\\ X_p \\end{pmatrix}^T \\begin{pmatrix} 0 &amp; 1 \\\\ -1 &amp; 0 \\end{pmatrix} \\begin{pmatrix} Y_q \\\\ Y_p \\end{pmatrix} \\implies \\Gamma = \\begin{pmatrix} 0 &amp; 1 \\\\ -1 &amp; 0 \\end{pmatrix} \\end{align}\\] The implicit equation expands out to \\[ \\omega (X_H, Y) = dH\\, Y = Y\\, H \\implies (X_H)^T \\Gamma Y = Y_q \\partial_{q} H + Y_p \\partial_{p} H = (\\nabla H)^T Y, \\quad \\forall Y \\] where we have identified \\(X_H, Y\\) with their \\(\\partial_{q}, \\partial_{p}\\) coordinate representations on the RHS. The previous equation implies \\[ (X_H)^T \\Gamma = (\\nabla H)^T \\iff \\nabla H = ((X_H)^T \\Gamma)^T = -\\Gamma X_H \\iff X_H = \\Gamma \\nabla_H \\] "],["bibliography.html", "Bibliography", " Bibliography "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
