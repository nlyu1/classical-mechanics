# Hamiltonian Mechanics 

We begin by enumerating three properties of the Legendre 
transform, which relates (convex) Lagrangians and Hamiltonians. 

Key takeaways of this part are: 

1. The Hamiltonian $H(q, p, t)$ is the Legendre transform of $\mca L(q, \dot q, t)$ 
    fixing $q, t$. 
2. Fixing $q, t$, the conjugate variables $\dot q$ and $p$ are functions 
    of each other by $\nabla_{\dot q} \mca L = p$ and $\dot q = \nabla_p H$ 
    (lemma \@ref(lem:legendreConjugateRelation)). 
    The Jacobian $J_{p\to q}$ is the Hessian. 
2. When the $\sup$ is dropped in the Legendre transform, 
    the two variables are always understood to obey an implicit equation.
3. On strictly convex functions, the Legendre transform preserves 
    convexity, and is involutary. 
4. 

## Legendre transform {-}

The Legendre transform is a general transform of functions 
which interactive particularly well with convex functions. 

:::{.definition name="Legendre transform"}
Given a function $f:\R^n\to \R$, its Legendre transform 
$\mbb L f: \R^n\to \R$ is 
\[ 
    (\mbb L f)(p) = \sup_x \, \la x, p\ra - f(x)
\] 
:::

### Convex functions {-}
Convex functions are characterized by 
\[ 
    f(\lambda x + \bar \lambda y) \leq \lambda f(x) + \bar \lambda f(y), \quad 
    \lambda \in [0, 1], \bar \lambda = 1 - \lambda 
\] 
assume they're well-behaved enough, they're equivalently defined by 
having positive (semi) definite second-derivatives (Hessian) at all points: 
\[ 
    (\mca H_x f)(\forall x) \geq 0, \quad 
    (\mca H_x f)_{ij}(x) = (\pd {x_i x_j}^2 f)(x)
\] 
Here $A\geq 0$ for matrix $A$ is understood 
as _all_ eigenvalues of $A$ being nonnegative. Convexity is further 
equivalent to 
\[ 
    \forall x, y: f(y) \geq \nabla f(x) \cdot (y - x)
\] 
The function $f$ is _strictly convex_ when the inequalities are strict. 

:::{.proposition}
The gradient map $x\mapsto (\nabla f)(x)$ is invertible 
if $f$ is strictly convex. 
:::
_Proof:_ For $x\neq y$, strict convexity implies 
\begin{align}
    \nabla f(x) \cdot (y-x) < f(y) - f(x), \quad 
    \nabla f(y) \cdot (x-y) < f(x) - f(y)
\end{align}
Suppose for contradiction that $\nabla f(x) = \nabla f(y)$, 
substituting $\nabla f(y)=\nabla f(x)$ in the last equation and 
multiplying both sides by $-1$ yields the contradiction 
\[ 
    \nabla f(x) (y-x) > f(y) - f(x)
\] 

### Properties of the Legendre transform {-}
We now show that the Legendre transform is well-behaved 
for strictly convex functions. 

Assuming $f$ well-behaved, the extremality condition is 
\[ 
    \nabla_x \la x, p\ra - f(x) 
    = p - \nabla_x f(x) = 0 \iff p = \nabla_x f 
\] 
This means that the $\sup$ may be dropped
<span style="color:green">
when it is understood that $x$ is an implict function of 
$p$ via the equation $p = \nabla_x f$ 
</span>: 
\[ 
    (\mbb L f)(p=\nabla_x f) = x\cdot p - f(x)
\] 

The following lemma will prove the Hamilton 
equation $\dot q = \nabla_p H$. 

:::{.lemma #legendreConjugateRelation name="two-way relation between x and p"}
Given a Legendre transform 
\[ 
    g(p) = (\mbb L f)(p) = \sup_x p\cdot x - f(x)
\] 
Then $p = \nabla_x f \iff x = \nabla_p g$. 
:::
_Proof:_ Assuming $p = \nabla_x f$, then we can 
drop the $\sup$ in the Legendre transform, yielding 
\[ 
    g(p) = p\cdot x - f(x)
\] 
Take the gradient w.r.t. $p$ on both sides; note that 
we need to invoke the chain rule since $p, x$ are related: 
\begin{align}
    \nabla_p g(p) 
    &= \nabla_p (p\cdot x - f(x)) 
    = x + J_{p\to x} p - J_{p\to x} (\nabla_x f)_{=p}
    = x 
\end{align}

:::{.proposition name="Jacobian of Legendre transform"}
The Jacobian of the Legendre transform $x\to p$ is the Hessian of $f$ 
\[ 
    J_{x\to p} = d_x p = d_x \left(\nabla_x f\right) = \mca H_x f 
\] 
:::

:::{.proposition name="convexity invariance"}
Suppose $f(x)$ is convex strictly convex so $\mca H_x f> 0$ 
(positive-definite) everywhere, then $\mbb L f$ 
is convex, i.e. $\mca H_p (\mbb L f)>0$. 
:::
_Proof:_ Computing the Hessian explicitly and recognize $\nabla_x f = p$
\begin{align}
    \mca H_p(\mbb L f) 
    &= d_p [\nabla_p (\mbb L f)] = d_p \left[
        x + J_{p\to x} p - J_{p\to x}\nabla_x f
    \right] \\ 
    &= d_p x = J_{p\to x} = J_{x\to p}^{-1} = \left(\mca H_x f\right)^{-1}
\end{align}
Convexity follows from the convexity of $\mca H_x f> 0$. 

:::{.proposition name="involutary"}
For convex $f$, the Legendre transform is involutary 
\[ 
    \mbb L \left[(\mbb L f)(p)\right] (x) = f(x)
\] 
:::
_Proof:_ Unroll the definition
\begin{align}
    \mbb L \left[(\mbb L f)(p)\right] (x)
    &= \mbb L \left[p\mapsto xp - f(x)\right] (x)\\ 
    &= xp - \left[p\mapsto xp - f(x)\right]\, p 
    = xp - xp - f(x) = f(x)
\end{align}
Note the dependence here: fixing $x$, we can fix $p=\nabla_x f$, which 
in turn determines $x$ in the inner Legendre transform. 


## Hamilton's equations {-}

:::{.definition name="Hamiltonian"}
Given the Lagrangian $\mca L(q, \dot q, t)$, the 
    Hamiltonian is the Legendre transform of $\dot q\mapsto p$ 
    holding $q$ fixed 
    \[ 
        H(q, p, t) = p\cdot \dot q - \mca L(q, \dot q(p), t)
    \] 
    where $p = \nabla_{\dot q} \mca L$ and $\dot q(p)$ 
    is the implicit inverse of this equation. 
:::

:::{.theorem name="Hamilton's equations"} 
The following equations are equivalent to the Euler-Lagrange 
    equations \@ref(def:eulerLagrange) when the Lagrangian 
    $\mca L(q, \dot q, t)$ is strictly convex in in $\dot q$: 
    \begin{aligned}
        \dot p 
        = -\nabla_q H, \quad \dot q 
        = \nabla_p H 
    \end{aligned}
    Collecting $\xi = q \oplus p$ and write
    $H(q, p, t) = H(\xi, t)$, we have the compact expression 
    \[ 
        \pd t \xi = \Gamma\,  \nabla_\xi H, \quad \Gamma 
        = \bigoplus \begin{pmatrix}
            0 & 1 \\ -1 & 0 
        \end{pmatrix}
    \] 
:::
_Proof:_ Take care that $\dot q, p$ are implicit functions of each other 
    and recognize $p=\nabla_{\dot q}\mca L$; holding $q$ fixed: 
    \begin{align}
        \nabla_p H(q, p, t) 
        &= \nabla_p \left[p\cdot \dot q - \mca L(q, \dot q(p), t)\right] \\ 
        &= \dot q + J_{p\to \dot q} p - J_{p\to \dot q}(\nabla_{\dot q}\mca L) 
        = \dot q 
    \end{align}
    For the second equation, we're holding $p$ fixed, but $\dot q$ is still 
    dependent upon $q$, then 
    \begin{align}
        \nabla_q H(q, p, t) 
        &= \nabla_q \left[
            p\cdot \dot q - \mca L(q, \dot q(p), t)
        \right] \\ 
        &= J_{q\to \dot q}p 
        - \nabla_q \mca L - J_{q\to \dot q} (\nabla_{\dot q}\mca L) 
        = - \nabla_q \mca L  \\ 
        \dot p 
        &= d_t \nabla_{\dot q}\mca L = \nabla_q \mca L 
    \end{align}
    the last equation holds by the Euler-Lagrange equations. 

<div style="color:green">
:::{.remark}
For those interested in differential geometry, 
Hamilton's equations $\pd t \xi = \Gamma \, \nabla_\xi H$ 
is the component representation of the following implicit 
equation which defines the vector field $X_H$ 
_generating the time-translation of the system_: 
\[ 
    \omega(X_H, \, \cdot\, ) = dH
\] 
Here $\omega= dq \wedge dp$ is the _symplectic form_ 
represented by $\Gamma$, and $dH$ is the differential of $H$. 
:::
</div>

<details>
<summary> optional material: relation between implicit 
and coordinate equation </summary>
Given a chart $x=(x_1, \cdots, x_n)$ on a manifold $M$ (like fixing 
a basis), a **vector field** $X$ can be understood as a _directional derivative_ 
operation that consumes a scalar function $f$ and outputs $X\, f$ (read as 
$X$ acting on $f$. The value of $(X\, f)(x)$ encodes how much $f$ 
changes along the direction of $X$ at location $x$. 
The representation of $X$ in this chart $x$ is then 
\[ 
    X = \sum_{j=1}^n X_j \pd j 
\] 
where each $X_j$ is a scalar function; in this representation, the 
action can be easily understood as 
\[ 
    (X\, f)(x) = \sum_{j=1}^n X_j \pd j f(x) = (X_j)\cdot \nabla f(x)
\] 
where $(X_j)$ is understood as a vector denoting the ``direction''; 
in this sense the chart $x$ also fixes a basis $\pd 1, \cdots \pd n$ 
for the space of vector fields (tangent bundle). 
Given a scalar function $f$, its **differential** $df$ eats a vector 
field and outputs a scalar (function)
\[
    df\, X = X\, f 
\] 
We can similarly consider a basis representation for the differentials 
(which live on the cotangent bundle) with the notation $d x_1, \cdots, dx_n$ 
\[ 
    df = \sum_{j=1}^N f_j dx_j, \quad dx_j\, \pd i = \delta_{ij}
\] 
The last piece we need is **the wedge product**: assuming a basis 
$B=\{\pd p, \pd q\}$ ($p$, $q$ are univariables), the symplectic form 
$\omega = dq \wedge dp$ consumes two arguments in $B$ and outputs a number 
subject to the following rules: 
\[ 
    (dq \wedge dp)(\pd a, \pd b) = \begin{cases}
        1 & (\pd a, \pd b) = \pd q, \pd p \\ 
        -1 & (\pd a, \pd b) = \pd p, \pd q \\ 
        0 & \text{otherwise}. 
    \end{cases}
\] 
and being linear in each of its arguments. 

Back to Hamilton's equation $\omega(X_H, \cdot) = dH$. 
Fix the basis $\{\pd q, \pd p\}$ (the order matters!)
and consider two vector fields 
\[ 
    X = X_q \pd q + X_p \pd p, \quad Y = Y_q \pd q + Y_p \pd p 
\] 
The representation $\Gamma$ of $\omega$ is read from the equation 
\begin{align}
    \omega(X, Y) 
    &= X_qY_q \omega(\pd q, \pd q)_{=0} + X_p Y_q \omega(\pd p, \pd q)_{=-1}
    + X_qY_p \omega (\pd q, \pd p)_{=1} + X_pY_p \omega (\pd p, \pd p)_{=0} \\ 
    &= X_qY_p - X_p Y_q 
    = \begin{pmatrix} X_q \\ X_p \end{pmatrix}^T 
    \begin{pmatrix}
        0 & 1 \\ -1 & 0 
    \end{pmatrix} \begin{pmatrix}
        Y_q \\ Y_p 
    \end{pmatrix} \implies \Gamma = \begin{pmatrix}
        0 & 1 \\ -1 & 0 
    \end{pmatrix}
\end{align}
The implicit equation expands out to 
\[ 
    \omega (X_H, Y) = dH\, Y = Y\, H \implies (X_H)^T \Gamma Y 
    = Y_q \pd q H + Y_p \pd p H = (\nabla H)^T Y, \quad \forall Y
\] 
where we have identified $X_H, Y$ with their $\pd q, \pd p$ coordinate 
representations on the RHS. The previous equation implies 
\[ 
    (X_H)^T \Gamma = (\nabla H)^T \iff \nabla H = ((X_H)^T \Gamma)^T 
    = -\Gamma X_H \iff X_H = \Gamma \nabla_H 
\] 
</details>